name: CI - Rust

on:
  push:
    branches: [main]
    paths:
      - '**.rs'
      - '**/Cargo.toml'
      - '**/Cargo.lock'
      - 'rust-toolchain.toml'
      - '.cargo/**'
      - 'Cross.toml'
      - 'clippy.toml'
      - 'rustfmt.toml'
      - 'scripts/verify-kani.sh'
      - 'scripts/check-kani-coverage.sh'
      - '.github/workflows/ci-rust.yml'
  pull_request:
    branches: [main]
    paths:
      - '**.rs'
      - '**/Cargo.toml'
      - '**/Cargo.lock'
      - 'rust-toolchain.toml'
      - '.cargo/**'
      - 'Cross.toml'
      - 'clippy.toml'
      - 'rustfmt.toml'
      - 'scripts/verify-kani.sh'
      - 'scripts/check-kani-coverage.sh'
      - '.github/workflows/ci-rust.yml'
  workflow_dispatch:

env:
  CARGO_TERM_COLOR: always

jobs:
  # Quick validation that all Kani proofs are in tier lists
  kani-coverage:
    name: Kani Proof Coverage
    runs-on: ubuntu-latest
    timeout-minutes: 5

    steps:
      - uses: actions/checkout@v6

      - name: Validate Kani proof coverage
        run: ./scripts/check-kani-coverage.sh
        # Ensures all #[kani::proof] functions are in tier lists in verify-kani.sh

  # Primary build and test job (cross-platform matrix)
  build:
    name: Build & Test (${{ matrix.os }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 30
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, windows-latest, macos-latest]

    steps:
      - uses: actions/checkout@v6

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable
        with:
          components: rustfmt, clippy

      - name: Install cargo-nextest
        uses: ./.github/actions/install-cargo-tool
        with:
          tool: cargo-nextest

      - name: Configure sccache
        id: sccache
        uses: mozilla-actions/sccache-action@v0.0.9
        continue-on-error: true

      - name: Verify sccache is working (Unix)
        id: sccache-check-unix
        if: steps.sccache.outcome == 'success' && runner.os != 'Windows'
        run: ./scripts/verify-sccache.sh
        continue-on-error: true

      - name: Verify sccache is working (Windows)
        id: sccache-check-windows
        if: steps.sccache.outcome == 'success' && runner.os == 'Windows'
        shell: bash
        run: ./scripts/verify-sccache.sh
        continue-on-error: true

      - name: Set sccache working status
        id: sccache-check
        shell: bash
        run: |
          # Assign GitHub expressions to variables (avoids shellcheck SC2193)
          unix_working="${{ steps['sccache-check-unix'].outputs.working }}"
          windows_working="${{ steps['sccache-check-windows'].outputs.working }}"
          if [ "$unix_working" == "true" ] || [ "$windows_working" == "true" ]; then
            echo "working=true" >> "$GITHUB_OUTPUT"
          else
            echo "working=false" >> "$GITHUB_OUTPUT"
          fi

      - name: Clear sccache env on failure
        if: steps.sccache.outcome != 'success' || steps.sccache-check.outputs.working != 'true'
        shell: bash
        run: |
          echo "RUSTC_WRAPPER=" >> "$GITHUB_ENV"
          echo "SCCACHE_GHA_ENABLED=" >> "$GITHUB_ENV"

      - name: Cache cargo registry and build
        uses: actions/cache@v5
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: build-${{ matrix.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            build-${{ matrix.os }}-cargo-

      - name: Build
        run: cargo build --verbose
        env:
          RUSTC_WRAPPER: ${{ steps.sccache-check.outputs.working == 'true' && 'sccache' || '' }}
          SCCACHE_GHA_ENABLED: ${{ steps.sccache-check.outputs.working == 'true' && 'true' || 'false' }}
          SCCACHE_IGNORE_SERVER_IO_ERROR: "1"
          SCCACHE_STARTUP_NOTIFY_TIMEOUT: "60"
          SCCACHE_IDLE_TIMEOUT: "0"

      - name: Build network test peer
        run: cargo build -p network-test-peer
        env:
          RUSTC_WRAPPER: ${{ steps.sccache-check.outputs.working == 'true' && 'sccache' || '' }}
          SCCACHE_GHA_ENABLED: ${{ steps.sccache-check.outputs.working == 'true' && 'true' || 'false' }}
          SCCACHE_IGNORE_SERVER_IO_ERROR: "1"
          SCCACHE_STARTUP_NOTIFY_TIMEOUT: "60"
          SCCACHE_IDLE_TIMEOUT: "0"

      - name: Run tests (nextest)
        run: cargo nextest run --profile ci --verbose
        env:
          RUSTC_WRAPPER: ${{ steps.sccache-check.outputs.working == 'true' && 'sccache' || '' }}
          SCCACHE_GHA_ENABLED: ${{ steps.sccache-check.outputs.working == 'true' && 'true' || 'false' }}
          SCCACHE_IGNORE_SERVER_IO_ERROR: "1"
          SCCACHE_STARTUP_NOTIFY_TIMEOUT: "60"
          SCCACHE_IDLE_TIMEOUT: "0"

      - name: Build docs
        run: cargo doc --verbose

      - name: Check formatting
        run: cargo fmt --check

      - name: Run clippy
        run: cargo clippy --all-targets -- -D warnings

  # Miri undefined behavior check (cross-platform, parallelized)
  #
  # Test distribution strategy (all platforms use 16 seeds for consistent UB detection):
  # - Linux: 7 jobs (~148+83+68+99+253+192+221 tests split for ~10-12 min each)
  # - Windows: 7 jobs (same split as Linux for consistency)
  # - macOS: 4 jobs (faster runners allow combining smaller groups)
  #
  # Test distribution (from analysis, ~1064 total tests):
  # - network::protocol: ~148 tests (14%)
  # - network::compression + rle::: ~83 tests (8%)
  # - input_queue::: ~68 tests (6%)
  # - hash:: + rng:: + checksum:: + time_sync::: ~99 tests (9%)
  # - sessions::: ~253 tests (24%)
  # - sync_layer:: + network::(other): ~192 tests (18%)
  # - error:: + tests:: + telemetry:: + frame_info:: + misc: ~221 tests (21%)
  #
  # Test filtering uses --skip patterns for robustness. Positive filters use
  # multiple test name arguments (libtest [FILTERS...] syntax).
  miri:
    name: Miri (${{ matrix.name }})
    runs-on: ${{ matrix.os }}
    timeout-minutes: 20
    strategy:
      fail-fast: false
      matrix:
        include:
          # ============================================================
          # Linux jobs (4 seeds each, split into 7 for parallelism)
          # ============================================================

          # Linux Job 1: Protocol tests only (largest test group: ~148 tests)
          - name: Linux - protocol
            os: ubuntu-latest
            seeds: "0..4"
            test_filter: "network::protocol"
            skip_filter: ""
            big_endian: false

          # Linux Job 2: Compression + RLE tests (~83 tests)
          - name: Linux - compression
            os: ubuntu-latest
            seeds: "0..4"
            test_filter: "MULTI:network::compression|rle::"
            skip_filter: ""
            big_endian: false

          # Linux Job 3: Input queue tests (~68 tests)
          - name: Linux - input_queue
            os: ubuntu-latest
            seeds: "0..4"
            test_filter: "input_queue::"
            skip_filter: ""
            big_endian: false

          # Linux Job 4: Core utility tests + big-endian verification
          # Runs: hash, rng, checksum, time_sync modules (~99 tests)
          - name: Linux - core + big-endian
            os: ubuntu-latest
            seeds: "0..4"
            test_filter: "MULTI:hash::|rng::|checksum::|time_sync::"
            skip_filter: ""
            big_endian: true

          # Linux Job 5: Sessions tests (~253 tests)
          - name: Linux - sessions
            os: ubuntu-latest
            seeds: "0..4"
            test_filter: "sessions::"
            skip_filter: ""
            big_endian: false

          # Linux Job 6: Sync layer + network other (~192 tests)
          # sync_layer (96) + network non-protocol/compression (96)
          - name: Linux - sync + network-other
            os: ubuntu-latest
            seeds: "0..4"
            test_filter: "MULTI:sync_layer::|network::chaos_socket|network::udp_socket|network::messages|network::codec|network::network_stats"
            skip_filter: ""
            big_endian: false

          # Linux Job 7: Error + tests + telemetry + frame_info + misc (~221 tests)
          - name: Linux - error + misc
            os: ubuntu-latest
            seeds: "0..4"
            test_filter: "MULTI:error::|tests::|telemetry::|frame_info::|sync::|test_config::"
            skip_filter: ""
            big_endian: false

          # ============================================================
          # Windows jobs (4 seeds each, split into 7 for parallelism)
          # ============================================================

          # Windows Job 1: Protocol tests only (~148 tests)
          - name: Windows - protocol
            os: windows-latest
            seeds: "0..4"
            test_filter: "network::protocol"
            skip_filter: ""
            big_endian: false

          # Windows Job 2: Compression + RLE tests (~83 tests)
          - name: Windows - compression
            os: windows-latest
            seeds: "0..4"
            test_filter: "MULTI:network::compression|rle::"
            skip_filter: ""
            big_endian: false

          # Windows Job 3: Input queue tests (~68 tests)
          - name: Windows - input_queue
            os: windows-latest
            seeds: "0..4"
            test_filter: "input_queue::"
            skip_filter: ""
            big_endian: false

          # Windows Job 4: Core utility tests (~99 tests)
          - name: Windows - core
            os: windows-latest
            seeds: "0..4"
            test_filter: "MULTI:hash::|rng::|checksum::|time_sync::"
            skip_filter: ""
            big_endian: false

          # Windows Job 5: Sessions tests (~253 tests)
          - name: Windows - sessions
            os: windows-latest
            seeds: "0..4"
            test_filter: "sessions::"
            skip_filter: ""
            big_endian: false

          # Windows Job 6: Sync layer + network other (~192 tests)
          # sync_layer (96) + network non-protocol/compression (96)
          - name: Windows - sync + network-other
            os: windows-latest
            seeds: "0..4"
            test_filter: "MULTI:sync_layer::|network::chaos_socket|network::udp_socket|network::messages|network::codec|network::network_stats"
            skip_filter: ""
            big_endian: false

          # Windows Job 7: Error + tests + telemetry + frame_info + misc (~221 tests)
          - name: Windows - error + misc
            os: windows-latest
            seeds: "0..4"
            test_filter: "MULTI:error::|tests::|telemetry::|frame_info::|sync::|test_config::"
            skip_filter: ""
            big_endian: false

          # ============================================================
          # macOS jobs (4 seeds each, split into 4 - faster runners)
          # ============================================================

          # macOS Job 1: Protocol + Compression (~148 + 83 = ~231 tests)
          - name: macOS - protocol + compression
            os: macos-latest
            seeds: "0..4"
            test_filter: "MULTI:network::protocol|network::compression|rle::"
            skip_filter: ""
            big_endian: false

          # macOS Job 2: Input queue + Core (~68 + 99 = ~167 tests)
          - name: macOS - input_queue + core
            os: macos-latest
            seeds: "0..4"
            test_filter: "MULTI:input_queue::|hash::|rng::|checksum::|time_sync::"
            skip_filter: ""
            big_endian: false

          # macOS Job 3: Sessions + sync_layer (~253 + 96 = ~349 tests)
          - name: macOS - sessions + sync
            os: macos-latest
            seeds: "0..4"
            test_filter: "MULTI:sessions::|sync_layer::"
            skip_filter: ""
            big_endian: false

          # macOS Job 4: Network other + error + misc (~96 + 221 = ~317 tests)
          - name: macOS - network-other + misc
            os: macos-latest
            seeds: "0..4"
            test_filter: "MULTI:network::chaos_socket|network::udp_socket|network::messages|network::codec|network::network_stats|error::|tests::|telemetry::|frame_info::|sync::|test_config::"
            skip_filter: ""
            big_endian: false

    steps:
      - uses: actions/checkout@v6

      - name: Install nightly with Miri
        uses: dtolnay/rust-toolchain@master
        with:
          toolchain: nightly
          components: miri

      - name: Cache cargo registry and build
        uses: actions/cache@v5
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          # Include matrix.name in cache key for job-specific caching
          key: miri-${{ matrix.os }}-${{ matrix.name }}-cargo-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            miri-${{ matrix.os }}-${{ matrix.name }}-cargo-
            miri-${{ matrix.os }}-cargo-

      - name: Setup Miri
        run: cargo miri setup

      - name: Run Miri tests
        shell: bash
        run: |
          set -e  # Exit on first error

          # Assign GitHub Actions expressions to bash variables (avoids shellcheck SC2193)
          test_filter="${{ matrix.test_filter }}"
          skip_filter="${{ matrix.skip_filter }}"

          # Handle MULTI: prefix for running multiple test groups
          # Uses pipe (|) as delimiter to avoid conflicts with Rust's :: module separator
          if [[ "$test_filter" == MULTI:* ]]; then
            # Extract pipe-separated filters (skip MULTI: prefix)
            filters="$test_filter"
            filters="${filters#MULTI:}"

            # Run cargo miri test for each filter
            IFS='|' read -ra FILTER_ARRAY <<< "$filters"
            for filter in "${FILTER_ARRAY[@]}"; do
              if [[ -n "$filter" ]]; then
                echo "Running tests matching: $filter"
                cargo miri test --lib -- "$filter" $skip_filter
              fi
            done
          elif [[ -n "$test_filter" ]]; then
            # Single positive filter
            cargo miri test --lib -- "$test_filter" $skip_filter
          else
            # No positive filter, just skip patterns
            cargo miri test --lib -- $skip_filter
          fi
        env:
          MIRIFLAGS: "-Zmiri-disable-isolation -Zmiri-many-seeds=${{ matrix.seeds }} -Zmiri-symbolic-alignment-check"

      - name: Run Miri tests (big-endian)
        if: matrix.big_endian
        run: cargo miri test --lib --target s390x-unknown-linux-gnu -- --skip property_tests
        env:
          MIRIFLAGS: "-Zmiri-disable-isolation"

  # MSRV (Minimum Supported Rust Version) verification
  msrv-check:
    name: MSRV Check
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v6

      - name: Extract MSRV from Cargo.toml
        id: cargo-msrv
        run: |
          MSRV=$(grep -E '^rust-version\s*=' Cargo.toml | sed 's/.*"\([^"]*\)".*/\1/')
          echo "msrv=$MSRV" >> "$GITHUB_OUTPUT"
          echo "Cargo.toml MSRV: $MSRV"

      - name: Extract Rust version from Dockerfile
        id: docker-rust
        run: |
          DOCKER_RUST=$(grep -E '^FROM rust:' docker/Dockerfile | sed 's/FROM rust:\([0-9.]*\).*/\1/')
          echo "docker_rust=$DOCKER_RUST" >> "$GITHUB_OUTPUT"
          echo "Dockerfile Rust: $DOCKER_RUST"

      - name: Verify MSRV matches Dockerfile
        run: |
          CARGO_MSRV="${{ steps.cargo-msrv.outputs.msrv }}"
          DOCKER_RUST="${{ steps.docker-rust.outputs.docker_rust }}"

          if [ "$CARGO_MSRV" != "$DOCKER_RUST" ]; then
            echo "❌ ERROR: MSRV mismatch!"
            echo "  Cargo.toml rust-version: $CARGO_MSRV"
            echo "  Dockerfile Rust version: $DOCKER_RUST"
            echo ""
            echo "The Dockerfile Rust version must match the Cargo.toml rust-version."
            echo "Update either docker/Dockerfile or Cargo.toml to fix this."
            exit 1
          fi

          echo "✅ MSRV versions match: $CARGO_MSRV"

      - name: Install MSRV toolchain
        uses: dtolnay/rust-toolchain@master
        with:
          toolchain: ${{ steps.cargo-msrv.outputs.msrv }}

      - name: Verify build with MSRV
        run: cargo check --all-targets
        env:
          RUSTUP_TOOLCHAIN: ${{ steps.cargo-msrv.outputs.msrv }}

  # Feature flag combinations check
  feature-checks:
    name: Feature Flag Matrix
    runs-on: ubuntu-latest

    steps:
      - uses: actions/checkout@v6

      - name: Install stable toolchain
        uses: dtolnay/rust-toolchain@master
        with:
          toolchain: stable

      - name: Install cargo-hack
        uses: ./.github/actions/install-cargo-tool
        with:
          tool: cargo-hack

      - name: Configure sccache
        id: sccache
        uses: mozilla-actions/sccache-action@v0.0.9
        continue-on-error: true

      - name: Verify sccache is working
        id: sccache-check
        if: steps.sccache.outcome == 'success'
        run: ./scripts/verify-sccache.sh
        continue-on-error: true

      - name: Clear sccache env on failure
        if: steps.sccache.outcome != 'success' || steps.sccache-check.outcome != 'success'
        run: |
          echo "RUSTC_WRAPPER=" >> "$GITHUB_ENV"
          echo "SCCACHE_GHA_ENABLED=" >> "$GITHUB_ENV"

      - name: Cache cargo registry and build
        uses: actions/cache@v5
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: feature-${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            feature-${{ runner.os }}-cargo-

      - name: Check feature powerset (excluding slow features)
        run: cargo hack check --feature-powerset --exclude-features z3-verification,z3-verification-bundled,graphical-examples
        env:
          RUSTC_WRAPPER: ${{ steps.sccache-check.outputs.working == 'true' && 'sccache' || '' }}
          SCCACHE_GHA_ENABLED: ${{ steps.sccache-check.outputs.working == 'true' && 'true' || 'false' }}
          SCCACHE_IGNORE_SERVER_IO_ERROR: "1"
          SCCACHE_STARTUP_NOTIFY_TIMEOUT: "60"
          SCCACHE_IDLE_TIMEOUT: "0"

  # Package dry-run
  package-dry-run:
    name: Package Dry Run
    runs-on: ubuntu-latest
    needs: build

    steps:
      - uses: actions/checkout@v6
      - name: Ensure crate is publishable (dry-run)
        run: cargo publish --dry-run

  # Semver compatibility check
  # Uses the official action which has built-in caching for baseline rustdoc
  semver-checks:
    name: Semver Check
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'

    steps:
      - uses: actions/checkout@v6

      # Use Swatinem/rust-cache for better Rust-specific caching
      # This caches ~/.cargo and target/ efficiently
      - name: Setup Rust cache
        uses: Swatinem/rust-cache@v2
        with:
          # Share cache with other Ubuntu jobs for faster builds
          shared-key: "ubuntu-cargo"
          # Cache only dependencies, not the main crate build artifacts
          cache-targets: "false"

      # Use the official cargo-semver-checks action which has built-in
      # rustdoc caching for both baseline and current versions
      - name: Check semver compatibility
        uses: obi1kenobi/cargo-semver-checks-action@v2
        continue-on-error: true  # Warn but don't fail - breaking changes are acceptable if documented

  # WASM build verification
  wasm-check:
    name: WASM Build Check
    runs-on: ubuntu-latest
    timeout-minutes: 15

    steps:
      - uses: actions/checkout@v6

      - name: Install Rust toolchain with WASM target
        uses: dtolnay/rust-toolchain@stable
        with:
          targets: wasm32-unknown-unknown
          components: clippy

      - name: Configure sccache
        id: sccache
        uses: mozilla-actions/sccache-action@v0.0.9
        continue-on-error: true

      - name: Verify sccache is working
        id: sccache-check
        if: steps.sccache.outcome == 'success'
        run: ./scripts/verify-sccache.sh
        continue-on-error: true

      - name: Clear sccache env on failure
        if: steps.sccache.outcome != 'success' || steps.sccache-check.outcome != 'success'
        run: |
          echo "RUSTC_WRAPPER=" >> "$GITHUB_ENV"
          echo "SCCACHE_GHA_ENABLED=" >> "$GITHUB_ENV"

      - name: Cache cargo registry and build
        uses: actions/cache@v5
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: wasm-${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            wasm-${{ runner.os }}-cargo-

      - name: Check WASM build (no default features)
        run: cargo check --target wasm32-unknown-unknown --no-default-features
        env:
          RUSTC_WRAPPER: ${{ steps.sccache-check.outputs.working == 'true' && 'sccache' || '' }}
          SCCACHE_GHA_ENABLED: ${{ steps.sccache-check.outputs.working == 'true' && 'true' || 'false' }}
          SCCACHE_IGNORE_SERVER_IO_ERROR: "1"
          SCCACHE_STARTUP_NOTIFY_TIMEOUT: "60"
          SCCACHE_IDLE_TIMEOUT: "0"

      - name: Check WASM build (with sync-send feature)
        run: cargo check --target wasm32-unknown-unknown --features sync-send
        env:
          RUSTC_WRAPPER: ${{ steps.sccache-check.outputs.working == 'true' && 'sccache' || '' }}
          SCCACHE_GHA_ENABLED: ${{ steps.sccache-check.outputs.working == 'true' && 'true' || 'false' }}
          SCCACHE_IGNORE_SERVER_IO_ERROR: "1"
          SCCACHE_STARTUP_NOTIFY_TIMEOUT: "60"
          SCCACHE_IDLE_TIMEOUT: "0"

      - name: Check WASM build (with paranoid feature)
        run: cargo check --target wasm32-unknown-unknown --features paranoid
        env:
          RUSTC_WRAPPER: ${{ steps.sccache-check.outputs.working == 'true' && 'sccache' || '' }}
          SCCACHE_GHA_ENABLED: ${{ steps.sccache-check.outputs.working == 'true' && 'true' || 'false' }}
          SCCACHE_IGNORE_SERVER_IO_ERROR: "1"
          SCCACHE_STARTUP_NOTIFY_TIMEOUT: "60"
          SCCACHE_IDLE_TIMEOUT: "0"

      - name: Check WASM build (with json feature)
        run: cargo check --target wasm32-unknown-unknown --features json
        env:
          RUSTC_WRAPPER: ${{ steps.sccache-check.outputs.working == 'true' && 'sccache' || '' }}
          SCCACHE_GHA_ENABLED: ${{ steps.sccache-check.outputs.working == 'true' && 'true' || 'false' }}
          SCCACHE_IGNORE_SERVER_IO_ERROR: "1"
          SCCACHE_STARTUP_NOTIFY_TIMEOUT: "60"
          SCCACHE_IDLE_TIMEOUT: "0"

      - name: Run clippy for WASM target
        run: cargo clippy --target wasm32-unknown-unknown --no-default-features -- -D warnings
        env:
          RUSTC_WRAPPER: ${{ steps.sccache-check.outputs.working == 'true' && 'sccache' || '' }}
          SCCACHE_GHA_ENABLED: ${{ steps.sccache-check.outputs.working == 'true' && 'true' || 'false' }}
          SCCACHE_IGNORE_SERVER_IO_ERROR: "1"
          SCCACHE_STARTUP_NOTIFY_TIMEOUT: "60"
          SCCACHE_IDLE_TIMEOUT: "0"

  # ARM64 (aarch64) cross-compilation verification
  arm64-cross:
    name: ARM64 Cross-Compile
    runs-on: ubuntu-latest
    timeout-minutes: 30
    # Override linker settings to use the default GCC cross-compiler instead of clang+lld.
    # This avoids needing to install extra tools in the cross-rs container.
    # The .cargo/config.toml specifies clang+lld for faster local builds, but
    # Cross.toml passes through these env vars so CI can override to GCC.
    #
    # RUSTFLAGS must be cleared because .cargo/config.toml sets "-C link-arg=-fuse-ld=lld"
    # which is incompatible with GCC (GCC doesn't understand the -fuse-ld=lld flag).
    #
    # IMPORTANT: We must ALSO override the x86_64 (host) target settings because proc-macro
    # crates and build scripts compile for the HOST machine, not the cross-compile target.
    # The .cargo/config.toml specifies `clang` as the linker for x86_64, but clang is NOT
    # installed in the cross-rs Docker container (where the build runs). Using `cc` works everywhere.
    env:
      # Target (aarch64) linker settings
      CARGO_TARGET_AARCH64_UNKNOWN_LINUX_GNU_LINKER: aarch64-linux-gnu-gcc
      CARGO_TARGET_AARCH64_UNKNOWN_LINUX_GNU_RUSTFLAGS: ""
      # Host (x86_64) linker settings - required for build scripts and proc-macros
      CARGO_TARGET_X86_64_UNKNOWN_LINUX_GNU_LINKER: cc
      CARGO_TARGET_X86_64_UNKNOWN_LINUX_GNU_RUSTFLAGS: ""

    steps:
      - uses: actions/checkout@v6

      - name: Cache cargo registry and build
        uses: actions/cache@v5
        with:
          path: |
            ~/.cargo/registry
            ~/.cargo/git
            target
          key: arm64-${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
          restore-keys: |
            arm64-${{ runner.os }}-cargo-

      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable

      - name: Install cross
        uses: ./.github/actions/install-cargo-tool
        with:
          tool: cross

      - name: Check ARM64 build (no default features)
        run: cross check --target aarch64-unknown-linux-gnu --no-default-features

      - name: Check ARM64 build (default features)
        run: cross check --target aarch64-unknown-linux-gnu

      - name: Check ARM64 build (with sync-send feature)
        run: cross check --target aarch64-unknown-linux-gnu --features sync-send

      - name: Check ARM64 build (with paranoid feature)
        run: cross check --target aarch64-unknown-linux-gnu --features paranoid

      - name: Check ARM64 build (with json feature)
        run: cross check --target aarch64-unknown-linux-gnu --features json

      - name: Check ARM64 build (with tokio feature)
        run: cross check --target aarch64-unknown-linux-gnu --features tokio

      - name: Run clippy for ARM64 target
        run: cross clippy --target aarch64-unknown-linux-gnu --no-default-features -- -D warnings

      - name: Build ARM64 release (verify full compilation)
        run: cross build --target aarch64-unknown-linux-gnu --release
